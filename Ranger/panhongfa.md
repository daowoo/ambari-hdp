# 大数据架构
## 问题引入
在大规模数据处理中，常遇到的一类问题是：在海量数据中找出出现频率最高的前K个数，或者从海量数据中找出最大的前K个数，这类问题通常称为“top K”问题，如：在搜索引擎中，统计搜索最热门的10个查询词；在歌曲库中统计下载率最高的前10首歌等等。

针对top k类问题，通常比较好的方案是先将数据集按照hash方法Split成多个小数据集，然后使用trie树或者hash统计每个小数据集中的query词频，之后用小顶堆求出每个数据集中出频率最高的前K个数，最后在所有top K中求出最终的top K。

## 解决方案
### 足够大内存，单机+单线程
假设每个查询词平均占8Byte，则10亿个查询词所需的内存大约是10^9*8=8G内存。如果你有这么大的内存，直接在内存中用HashMap求出每个词出现的频率，然后求出出现频率最大的10个词。

### 足够大内存，单机+多线程
这种情况下，直接在内存中实用hash方法将数据划分成c*n个partition（c>1），每个partition交给一个线程处理，每个线程处理完当前partition后主动取下一个partition继续处理，直到所有数据处理完毕，最后由一个线程进行归并。

### 受限内存，单机+拆分+多线程
这种情况下，需要将原数据文件切割成一个一个小文件，如，采用hash(x)%M，将原文件中的数据切割成M个小文件，如果小文件仍大于内存大小，继续采用hash的方法对数据文件进行切割，直到每个小文件小于内存大小，这样，每个文件可放到内存中处理。然后再依次对小文件采用划分partition，多线程主动获取partition，然后归并结果的方式，逐个文件完成处理。

### 受限内存，多机
这种情况下，为了合理利用多台机器的资源，可将数据分发到多台机器上，每台机器采用单机+拆分+多线程中的策略解决本地的数据。可采用hash+socket方法进行数据分发。

### hadoop集群方式
这种情况下，首先将文件Put到HDFS文件系统，然后采用MapReduce框架解决，只需编写一个map函数和两个reduce 函数，然后提交到Hadoop上即可解决该问题。对于map函数，采用hash算法，将hash值相同的数据交给同一个reduce task；对于第一个reduce函数，采用HashMap统计出每个词出现的频率，对于第二个reduce 函数，统计所有reduce task输出数据中的top k即可。

但在实际应用的角度考虑，这些方案并不可行，因为在大规模数据处理环境下，作业效率并不是首要考虑的问题，算法的扩展性和容错性才是首要考虑的。算法应该具有良好的扩展性，以便数据量进一步加大（随着业务的发展，数据量加大是必然的）时，在不修改算法框架的前提下，可达到近似的线性比；算法应该具有容错性，即当前某个文件处理失败后，能自动将其交给另外一个线程继续处理，而不是从头开始处理。

## Hadoop生态圈
