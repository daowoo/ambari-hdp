# ProtoBuff,Thrift和Avro比较
本质上来看，它们都是为了在不同系统、不同编程语言之间支持实现RPC调用而设计出的数据序列化机制，都支持使用IDL描述语言来描述服务接口的Schema，然后通过编译工具生成若干编程语言的代码。我们着重来分析它们在功能上存在的差异。

## 以前的跨语言通信方案
|             方案              |                      缺点                      |
| ----------------------------- | ---------------------------------------------- |
| 基于SOAP消息格式的WebService  | XML体积太大，解析性能较差                      |
| 基于JSON消息格式的RESTful服务 | JSON体积相对较小，解析相对较快，但表达能力较弱 |

## 当前流行的跨语言通信框架
### Google protobuf
#### 优点
* 二进制消息，性能好/效率高（空间和时间效率都很不错）
* proto文件编译生成目标代码，简单易用
* 序列化反序列化直接对应程序中的数据类，不需要解析后在进行映射(XML,JSON都是映射方式)
* 支持向前兼容（新加字段采用默认值）和向后兼容（忽略新加字段），简化升级
* 支持多种语言（可以把proto文件看做IDL文件）
* Netty等一些框架集成

#### 缺点
* 官方只支持C++,JAVA和Python语言绑定
* 二进制可读性差（貌似提供了Text_Fromat功能）
* 二进制不具有自描述特性
* 默认不具备动态特性（可以通过动态定义生成消息类型或者动态编译支持）
* 只涉及序列化和反序列化技术，不涉及RPC功能（类似XML或者JSON的解析器）

#### 场景
* 对传输数据量大小比较敏感，效率至上的应用最适合

### Apache Thrift
#### 优点
* 支持非常多的语言绑定
* thrift文件生成目标代码，简单易用
* 消息定义文件支持注释
* 数据结构与传输表现的分离，支持多种消息格式
* 包含完整的客户端/服务端堆栈，可快速实现RPC
* 支持同步和异步通信

#### 缺点
* 和protobuf一样不支持动态特性

#### 场景
* 需要支持多种语言，不关注通信细节或对通信效率要求一般的应用最适合

### Apache Avro
#### 优点
* 二进制消息，性能好/效率高
* 使用JSON描述模式
* 模式和数据统一存储，消息自描述，不需要生成stub代码（支持生成IDL）
* RPC调用在握手阶段交换模式定义
* 包含完整的客户端/服务端堆栈，可快速实现RPC
* 支持同步和异步通信
* 支持动态消息
* 模式定义允许定义数据的排序（序列化时会遵循这个顺序）
* 提供了基于Jetty内核的服务基于Netty的服务

#### 缺点
* 只支持Avro自己的序列化格式
* 语言绑定不如Thrift丰富

#### 场景
* 其动态消息的特性，非常适合在hadoop大数据平台上使用
